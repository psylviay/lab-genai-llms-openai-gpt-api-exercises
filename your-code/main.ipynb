{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))  # Should print the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot initialized. Ask me anything about history!\n",
      "Type 'exit' to end the chat.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Who discovered the New World?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Christopher Columbus is traditionally credited with the discovery of the New World in 1492 when he landed in the Bahamas while searching for a new route to Asia. However, it is important to note that the Americas were already inhabited by indigenous peoples who had been living there for thousands of years before Columbus arrived.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Creates a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).\n",
    "\n",
    "# Loads the necessary libraries\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Sets the OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OpenAI_API_KEY\")\n",
    "\n",
    "# Initializes the OpenAI client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def chatbot(topic=\"technology\"):\n",
    "    print(f\"Chatbot initialized. Ask me anything about {topic}!\")\n",
    "    print(\"Type 'exit' to end the chat.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Parameters to experiment with\n",
    "        temperature = 0.7  # Controls randomness (0 = deterministic, 1 = creative)\n",
    "        \n",
    "        max_tokens = 100  # Limits response length\n",
    "        \n",
    "        top_p = 0.9  # Controls diversity (higher = more diverse)\n",
    "        \n",
    "        frequency_penalty = 0.5  # Discourages word repetition\n",
    "        \n",
    "        presence_penalty = 0.5  # Encourages the introduction of new topics\n",
    "        \n",
    "        n = 1  # Specifies the number of completions to generate\n",
    "        \n",
    "        stop = None  # Stop sequence (e.g., [\"\\n\", \"User:\"]) to control response cutoff\n",
    "\n",
    "        # Creates prompt\n",
    "        prompt = f\"You are a helpful AI chatbot that answers questions about {topic}.\\nUser: {user_input}\\nChatbot:\"\n",
    "\n",
    "        # Gets the response from OpenAIexit\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"system\", \"content\": f\"You are an expert in {topic}.\"},\n",
    "                      {\"role\": \"user\", \"content\": user_input}],\n",
    "            temperature=temperature,                # Controls creativity\n",
    "            max_tokens=max_tokens,                  # Limits response length\n",
    "            top_p=top_p,                            # Controls response diversity\n",
    "            frequency_penalty=frequency_penalty,    # Avoids word repetition\n",
    "            presence_penalty=presence_penalty,      # Encourages new words\n",
    "            n=n,                                    # Generates multiple responses \n",
    "            stop=stop                               # Controls where the response ends\n",
    "        )\n",
    "\n",
    "        # Extracts the answer\n",
    "        answer = response.choices[0].message.content\n",
    "        print(f\"Chatbot: {answer}\")\n",
    "\n",
    "# Runs chatbot on a given topic\n",
    "chatbot(\"history\")  # Change topic here (e.g., \"technology\", \"science\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text to summarize. Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  The first trailer for Marvel's \"The Fantastic Four: First Steps\" dropped Tuesday, giving fans a first look at the longtime superhero family from the comic books debuting in the Marvel Cinematic Universe. And things are very retrofuturistic, a nod to the Fantastic Four's 1960s-era origins.  \"First Steps\" (in theaters July 25) follows a quartet of astronauts given extraordinary abilities courtesy of cosmic rays: super-stretchy leader Reed Richards (Pedro Pascal), invisible woman Sue Storm (Vanessa Kirby), human torch Johnny Storm (Joseph Quinn) and rock monster Ben Grimm, aka The Thing (Ebon Moss-Bachrach).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing your request...\n",
      "\n",
      "Summarizing your input... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully!\n",
      "\n",
      "=== Summary ===\n",
      "The trailer for Marvel's \"The Fantastic Four: First Steps\" introduces the superhero family in a retrofuturistic style, paying homage to their 1960s origins. The movie follows a quartet of astronauts who gain superpowers from cosmic rays: Reed Richards, Sue Storm, Johnny Storm, and Ben Grimm. It is set to release in theaters on July 25.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting program. Thank you for using the summarizer!\n"
     ]
    }
   ],
   "source": [
    "# Takes a long text input and summarizes it into a few sentences.\n",
    "# Uses the OpenAI API\n",
    "\n",
    "# Loads the necessary libraries\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Sets the OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OpenAI_API_KEY\")\n",
    "\n",
    "# Initializes the OpenAI client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Sets the maximum text length to prevent long processing times\n",
    "MAX_INPUT_LENGTH = 5000  \n",
    "\n",
    "def summarize_text(long_text):\n",
    "    \"\"\"\n",
    "    Summarizes a given long text into a few sentences.\n",
    "    \"\"\"\n",
    "    print(\"\\nSummarizing your input... Please wait.\")  # Informs the user that summarization is in progress\n",
    "\n",
    "    # Ensures input is within safe limits\n",
    "    if len(long_text) > MAX_INPUT_LENGTH:\n",
    "        print(\"\\nInput text is too long! Trimming to fit the limit...\")\n",
    "        long_text = long_text[:MAX_INPUT_LENGTH]  # Trims the response to the value in max length\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()  # Tracks start time\n",
    "\n",
    "        print(\"Sending request to OpenAI API...\")  # Process status message\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Specifies the model to use. May be changed depending on the access granted in the OpenAI account.\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant that summarizes long texts into concise summaries.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Summarize the following text:\\n\\n{long_text}\"}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=150,\n",
    "            top_p=0.9,\n",
    "            frequency_penalty=0.5,\n",
    "            presence_penalty=0.5\n",
    "        )\n",
    "\n",
    "        print(\"Response received from OpenAI API.\")  # Status message\n",
    "\n",
    "        # Ensures the request does not take too long\n",
    "        if time.time() - start_time > 30:  # Sets the timeout to 30 seconds\n",
    "            print(\"Request took too long. Please try again with a shorter input.\")\n",
    "            return \"Summarization failed due to timeout.\"\n",
    "\n",
    "        # Extracts the summarized text\n",
    "        summary = response.choices[0].message.content.strip()\n",
    "        \n",
    "        print(\"\\nRequest completed successfully!\")  # Confirmation message\n",
    "        return summary\n",
    "\n",
    "    except openai.OpenAIError as e:  # Catches API errors\n",
    "        print(f\"\\n OpenAI API Error: {e}\")\n",
    "        return \"Summarization failed due to an API error.\"\n",
    "\n",
    "# Processes each input immediately\n",
    "print(\"Enter text to summarize. Type 'exit' to quit.\")\n",
    "while True:\n",
    "    long_text = input(\"\\nEnter your text: \")\n",
    "    \n",
    "    if long_text.lower() == \"exit\":\n",
    "        print(\"\\nExiting program. Thank you for using the summarizer!\")\n",
    "        break\n",
    "\n",
    "    if long_text.strip():\n",
    "        print(\"\\nProcessing your request...\")  # Status message\n",
    "        summary = summarize_text(long_text)\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(summary)  # Displays the summarized text\n",
    "    else:\n",
    "        print(\"\\nNo text provided. Please enter a valid input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text in English to translate to Spanish. Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  Life is beautiful. Love is kind.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing your request...\n",
      "\n",
      "Translating your input... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully!\n",
      "\n",
      "=== Spanish Translation ===\n",
      "La vida es hermosa. El amor es amable.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting program. Thank you for using the translator!\n"
     ]
    }
   ],
   "source": [
    "# Creates a tool that translates text from one language to another using the OpenAI API.\n",
    "\n",
    "# Loads the necessary libraries\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Sets the OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OpenAI_API_KEY\")\n",
    "\n",
    "# Initializes the OpenAI client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Maximum text length to prevent long processing times\n",
    "MAX_INPUT_LENGTH = 5000  \n",
    "\n",
    "def translate_text(text):\n",
    "    \"\"\"\n",
    "    Translates a given English text into Spanish.\n",
    "    \"\"\"\n",
    "    print(\"\\nTranslating your input... Please wait.\")  # Message to inform the user that translation is in progress\n",
    "\n",
    "    # Ensures input is within safe limits\n",
    "    if len(text) > MAX_INPUT_LENGTH:\n",
    "        print(\"\\nInput text is too long! Trimming to fit the limit...\")\n",
    "        text = text[:MAX_INPUT_LENGTH]  # Trims to max length\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()  # Tracks start time\n",
    "\n",
    "        print(\"Sending request to OpenAI API...\")  \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Specifies the model to use; may be changed depending on the access granted in the OpenAI account.\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant that translates English text to Spanish.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Translate the following English text into Spanish:\\n\\n{text}\"}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=250,  # Adjusted for translation output\n",
    "            top_p=0.9,\n",
    "            frequency_penalty=0.5,\n",
    "            presence_penalty=0.5\n",
    "        )\n",
    "\n",
    "        print(\"Response received from OpenAI API.\")  # Debugging message\n",
    "\n",
    "        # Makes sure the request does not take too long\n",
    "        if time.time() - start_time > 30:           # Timeout set to 30 seconds\n",
    "            print(\" Request took too long. Please try again with a shorter input.\")\n",
    "            return \"Translation failed due to timeout.\"\n",
    "\n",
    "        # Extracts the translated text\n",
    "        translation = response.choices[0].message.content.strip()\n",
    "        \n",
    "        print(\"\\nRequest completed successfully!\")  # Confirmation message\n",
    "        return translation\n",
    "\n",
    "    except openai.OpenAIError as e:  # Catches API errors\n",
    "        print(f\"\\n OpenAI API Error: {e}\")\n",
    "        return \"Translation failed due to an API error.\"\n",
    "\n",
    "# Processes each input immediately\n",
    "print(\"Enter text in English to translate to Spanish. Type 'exit' to quit.\")\n",
    "while True:\n",
    "    text = input(\"\\nEnter your text: \")\n",
    "    \n",
    "    if text.lower() == \"exit\":\n",
    "        print(\"\\nExiting program. Thank you for using the translator!\")\n",
    "        break\n",
    "\n",
    "    if text.strip():\n",
    "        print(\"\\nProcessing your request...\")     # Message before translation starts\n",
    "        translation = translate_text(text)\n",
    "        print(\"\\n=== Spanish Translation ===\")\n",
    "        print(translation)  # Displays the translated text\n",
    "    else:\n",
    "        print(\"\\nNo text provided. Please enter a valid input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the Parameters\n",
    "\n",
    "- lower temperature values provide more accurate, predictable and literal translations. Higher values result in more paraphrased translations and potentially altered sentence structure. For accurate translations 0.3 works great; only increase if more flexible results are desired.\n",
    "\n",
    "- lower token values (50-100) result in shorter, cut-off translations. Higher values result in longer, more complete translations.\n",
    "\n",
    "- if the max_tokens are too low, it may result in truncated outputs. Sentence translations should be at 150-200 and for paragraphs, 300-500\n",
    "\n",
    "- lower top_p values result in safer translations, higher values (0.8-1.0) in less predictable phrasing. A value of 0.9 provides good balance of accuracy and diversity. Also, if a high temperature (greater than or equal to 0.7) is used, reduce the top_p to avoid overly random results.\n",
    "\n",
    "- lower frequency_penalty values may result in repeat words within longer translations. Higher values avoid repeated words, but may result in unnatural translations.\n",
    "\n",
    "- lower presence_penalty values sticks closely to the input text. Higher values result in more diverse vocabulary and new words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text to analyze sentiment. Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  La vida es bella. El amor es amable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing your request...\n",
      "\n",
      "Analyzing sentiment... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully!\n",
      "\n",
      "=== Sentiment Analysis Result ===\n",
      "Positive\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting program. Thank you for using the sentiment analysis tool!\n"
     ]
    }
   ],
   "source": [
    "# Creates a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).\n",
    "\n",
    "# Loads the necessary libraries\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Sets the OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OpenAI_API_KEY\")\n",
    "\n",
    "# Initializes the OpenAI client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Maximum text length to prevent long processing times\n",
    "MAX_INPUT_LENGTH = 5000  \n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    Determines the sentiment of a given text (Positive, Negative, Neutral).\n",
    "    \"\"\"\n",
    "    print(\"\\nAnalyzing sentiment... Please wait.\")  # Message to inform the user that sentiment analysis is in progress\n",
    "\n",
    "    # Ensures input is within safe limits\n",
    "    if len(text) > MAX_INPUT_LENGTH:\n",
    "        print(\"\\nInput text is too long! Trimming to fit the limit...\")\n",
    "        text = text[:MAX_INPUT_LENGTH]              # Trims to max length\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()                   # Tracks start time\n",
    "\n",
    "        print(\"Sending request to OpenAI API...\")  # Debugging message\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Specifies the model to use; may be changed depending on the access granted in the OpenAI account.\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant that performs sentiment analysis. You classify text as Positive, Negative, or Neutral.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Analyze the sentiment of the following text and classify it as Positive, Negative, or Neutral:\\n\\n{text}\"}\n",
    "            ],\n",
    "            temperature=0.3,  # Controls randomness (lower = more deterministic)\n",
    "            max_tokens=10,  # Short response, just the classification\n",
    "            top_p=0.9,  # Controls response diversity\n",
    "            frequency_penalty=0.5,  # Reduces repetition\n",
    "            presence_penalty=0.5,  # Encourages diverse wording\n",
    "            n=1,  # Number of completions to generate\n",
    "            logprobs=True  # Returns probability scores (optional, for debugging)\n",
    "        )\n",
    "\n",
    "        print(\"Response received from OpenAI API.\")  # Debugging message\n",
    "\n",
    "        # Makes sure the request does not take too long\n",
    "        if time.time() - start_time > 30:  # Timeout set to 30 seconds\n",
    "            print(\" Request took too long. Please try again with a shorter input.\")\n",
    "            return \"Sentiment analysis failed due to timeout.\"\n",
    "\n",
    "        # Extracts the sentiment classification\n",
    "        sentiment = response.choices[0].message.content.strip()\n",
    "        \n",
    "        print(\"\\nRequest completed successfully!\")  # Confirmation message\n",
    "        return sentiment\n",
    "\n",
    "    except openai.OpenAIError as e:                # Catches API errors\n",
    "        print(f\"\\n OpenAI API Error: {e}\")\n",
    "        return \"Sentiment analysis failed due to an API error.\"\n",
    "\n",
    "# Processes each input immediately\n",
    "print(\"Enter text to analyze sentiment. Type 'exit' to quit.\")\n",
    "while True:\n",
    "    text = input(\"\\nEnter your text: \")\n",
    "    \n",
    "    if text.lower() == \"exit\":\n",
    "        print(\"\\nExiting program. Thank you for using the sentiment analysis tool!\")\n",
    "        break\n",
    "\n",
    "    if text.strip():\n",
    "        print(\"\\nProcessing your request...\")     # Message before sentiment analysis starts\n",
    "        sentiment = analyze_sentiment(text)\n",
    "        print(\"\\n=== Sentiment Analysis Result ===\")\n",
    "        print(sentiment)  # Displays the sentiment classification\n",
    "    else:\n",
    "        print(\"\\nNo text provided. Please enter a valid input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the Parameters\n",
    "\n",
    "- temperature: lower values provide more consistent and accurate sentiment classifications.\n",
    "- max_tokens: lower values result in shorter, precise responses, higher values might provide unnecessary explanations.\n",
    "- top_p: lower values (0.1-0.5) provide less diverse, more focused responses. Higher values may introduce variability in the classification.\n",
    "- frequency_penalty: lower values may result in repeat words within longer responses. Higher values can sometimes result in unnatural responses.\n",
    "- presence_penalty: lower values (0-0.3) provides results close to the standard classifications. Higher values may insert new and varied responses.\n",
    "- n: an n=1 results in only one sentiment classification. A value of 3 could be useful for comparisons as it returns 3 possible classifications.\n",
    "- -logprobs: A value of 5 can be useful for detailed analysis purposes but should be removed for normal use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt to generate text. Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt:  Puerto Rico\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing your request...\n",
      "\n",
      "Generating text... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully!\n",
      "\n",
      "=== Generated Text ===\n",
      "Puerto Rico is an unincorporated territory of the United States located in the northeastern Caribbean Sea. It is known for its beautiful beaches, vibrant culture, and rich history. The island is a popular tourist destination, attracting visitors with its warm weather, tropical landscapes, and delicious cuisine. Puerto Rico has a unique blend of Spanish, African, and Taino influences that can be seen in its music, dance, and art. The people of Puerto Rico are known for their hospitality and strong sense\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting program. Thank you for using the text generator!\n"
     ]
    }
   ],
   "source": [
    "# Creates a text completion application that generates text based on an initial prompt.\n",
    "\n",
    "# Loads the necessary libraries\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Sets the OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OpenAI_API_KEY\")\n",
    "\n",
    "# Initializes the OpenAI client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Sets the maximum text length to prevent long processing times\n",
    "MAX_INPUT_LENGTH = 1000  \n",
    "\n",
    "def generate_text(prompt):\n",
    "    \"\"\"\n",
    "    Generates text based on an initial prompt using OpenAI's chat model.\n",
    "    \"\"\"\n",
    "    print(\"\\nGenerating text... Please wait.\")  # Status message\n",
    "\n",
    "    # Ensures input is within safe limits\n",
    "    if len(prompt) > MAX_INPUT_LENGTH:\n",
    "        print(\"\\nInput prompt is too long! Trimming to fit the limit...\")\n",
    "        prompt = prompt[:MAX_INPUT_LENGTH]  # Trims the response to the max length\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()  # Tracks start time\n",
    "\n",
    "        print(\"Sending request to OpenAI API...\")  # Status message\n",
    "        response = client.chat.completions.create(  \n",
    "            model=\"gpt-3.5-turbo\",  # Specifies the chat model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI that generates text based on a given prompt.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,                       # Controls randomness\n",
    "            max_tokens=100,                        # Limits response length\n",
    "            top_p=0.9,                             # Controls response diversity\n",
    "            frequency_penalty=0.5,                 # Reduces word repetition\n",
    "            presence_penalty=0.5,                  # Encourages introducing new topics\n",
    "            n=3,                                   # Generates multiple responses to choose from\n",
    "            stop=None,                             # Defines stopping sequences\n",
    "        )\n",
    "\n",
    "        print(\"Response received from OpenAI API.\")# Status message\n",
    "\n",
    "        # Makes sure the request does not take too long\n",
    "        if time.time() - start_time > 30:          # Timeout set to 30 seconds\n",
    "            print(\"Request took too long. Please try again with a shorter input.\")\n",
    "            return \"Text generation failed due to timeout.\"\n",
    "\n",
    "        # Extracts the best response from the generated completions\n",
    "        generated_texts = [choice.message.content.strip() for choice in response.choices]\n",
    "        \n",
    "        print(\"\\nRequest completed successfully!\")  # Confirmation message\n",
    "\n",
    "        # Picks the most suitable response (can be refined based on additional criteria)\n",
    "        best_response = max(generated_texts, key=len)  # Chooses the longest response as the best\n",
    "        return best_response\n",
    "\n",
    "    except openai.OpenAIError as e:  # Catches API errors\n",
    "        print(f\"\\n OpenAI API Error: {e}\")\n",
    "        return \"Text generation failed due to an API error.\"\n",
    "\n",
    "# Processes each input immediately\n",
    "print(\"Enter a prompt to generate text. Type 'exit' to quit.\")\n",
    "while True:\n",
    "    prompt = input(\"\\nEnter your prompt: \")\n",
    "    \n",
    "    if prompt.lower() == \"exit\":\n",
    "        print(\"\\nExiting program. Thank you for using the text generator!\")\n",
    "        break\n",
    "\n",
    "    if prompt.strip():\n",
    "        print(\"\\nProcessing your request...\")  # Status message\n",
    "        generated_text = generate_text(prompt)\n",
    "        print(\"\\n=== Generated Text ===\")\n",
    "        print(generated_text)  # Displays the best-generated text\n",
    "    else:\n",
    "        print(\"\\nNo prompt provided. Please enter a valid input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the Parameters\n",
    "\n",
    "- temperature: controls the creativity\n",
    "- max_tokens: limits the response length\n",
    "- top_p: controls response diversity\n",
    "- frequency_penalty: avoids word repetition\n",
    "- presence_penalty: encourages new words\n",
    "- n: generates multiple responses\n",
    "- stop: controls where the response ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 (TensorFlow)",
   "language": "python",
   "name": "pyenv_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
