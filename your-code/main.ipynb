{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))  # Should print the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot initialized on **history**. Ask me anything!\n",
      "Type **'settings'** to adjust parameters, or **'exit'** to end the chat.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  settings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üõ†Ô∏è Adjust Chatbot Parameters:\n",
      "1Ô∏è‚É£ Temperature (0: deterministic, 1: creative) | Current: 0.7\n",
      "2Ô∏è‚É£ Max Tokens (Response length) | Current: 100\n",
      "3Ô∏è‚É£ Top-p (Controls diversity) | Current: 0.9\n",
      "4Ô∏è‚É£ Frequency Penalty (Repetition reduction) | Current: 0.5\n",
      "5Ô∏è‚É£ Presence Penalty (Encourages new topics) | Current: 0.5\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter new temperature (0-1):  0.2\n",
      "Enter max tokens (e.g., 50-300):  100\n",
      "Enter new top-p (0-1):  .5\n",
      "Enter frequency penalty (0-1):  .5\n",
      "Enter presence penalty (0-1):  .5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings updated successfully!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  Who is the King of England?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Chatbot: As of my last update, the current monarch of England is Queen Elizabeth II.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Imports necessary libraries\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# Loads API key from environment variable\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"API key not found! Ensure it's set in your .env file.\")\n",
    "\n",
    "# Initializes OpenAI Client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Defines a function to run the chatbot with adjustable parameters\n",
    "def chatbot(topic=\"technology\"):\n",
    "    print(f\"Chatbot initialized on **{topic}**. Ask me anything!\")\n",
    "    print(\"Type **'settings'** to adjust parameters, or **'exit'** to end the chat.\")\n",
    "\n",
    "    # Default Parameter Settings\n",
    "    temperature = 0.7\n",
    "    max_tokens = 100\n",
    "    top_p = 0.9\n",
    "    frequency_penalty = 0.5\n",
    "    presence_penalty = 0.5\n",
    "\n",
    "    # Defines a function to update chatbot parameters\n",
    "    def update_parameters():\n",
    "        nonlocal temperature, max_tokens, top_p, frequency_penalty, presence_penalty\n",
    "\n",
    "        print(\"\\nüõ†Ô∏è Adjust Chatbot Parameters:\")\n",
    "        print(\"1Ô∏è‚É£ Temperature (0: deterministic, 1: creative) | Current:\", temperature)\n",
    "        print(\"2Ô∏è‚É£ Max Tokens (Response length) | Current:\", max_tokens)\n",
    "        print(\"3Ô∏è‚É£ Top-p (Controls diversity) | Current:\", top_p)\n",
    "        print(\"4Ô∏è‚É£ Frequency Penalty (Repetition reduction) | Current:\", frequency_penalty)\n",
    "        print(\"5Ô∏è‚É£ Presence Penalty (Encourages new topics) | Current:\", presence_penalty)\n",
    "\n",
    "        try:\n",
    "            temperature = float(input(\"Enter new temperature (0-1): \") or temperature)\n",
    "            max_tokens = int(input(\"Enter max tokens (e.g., 50-300): \") or max_tokens)\n",
    "            top_p = float(input(\"Enter new top-p (0-1): \") or top_p)\n",
    "            frequency_penalty = float(input(\"Enter frequency penalty (0-1): \") or frequency_penalty)\n",
    "            presence_penalty = float(input(\"Enter presence penalty (0-1): \") or presence_penalty)\n",
    "            print(\"Settings updated successfully!\\n\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input! Keeping previous settings.\")\n",
    "\n",
    "    # Main Chat Loop\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \")\n",
    "\n",
    "        # Allows the user to exit\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Allows the user to change settings\n",
    "        if user_input.lower() == \"settings\":\n",
    "            update_parameters()\n",
    "            continue\n",
    "\n",
    "        # Generates a chatbot response\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"You are an expert in {topic}.\"},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=top_p,\n",
    "            frequency_penalty=frequency_penalty,\n",
    "            presence_penalty=presence_penalty,\n",
    "        )\n",
    "\n",
    "        # Extracts and prints the response\n",
    "        answer = response.choices[0].message.content\n",
    "        print(f\"ü§ñ Chatbot: {answer}\")\n",
    "\n",
    "# Runs the chatbot with history as the default topic\n",
    "chatbot(\"history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text to summarize. Type **'settings'** to adjust parameters or **'exit'** to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  ‚ÄúShe was my biggest fan, greatest supporter, without her none of my personal achievements would have been possible. She was loved by so many, but especially by her two grandchildren, Sam and Charlie.‚Äù  Tiger Woods thanked his fans for their support and prayers and asked for privacy ‚Äúat this difficult time for me and my family.‚Äù  The 82-time PGA Tour winner ended his message with: ‚ÄúLove you Mom.‚Äù\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing your request...\n",
      "\n",
      " **Default Settings Summary:**\n",
      "\n",
      "üìù Summarizing your input... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully!\n",
      "\n",
      "=== Summary (Default) ===\n",
      "Tiger Woods expressed gratitude for his mother's support and love, acknowledging her as his biggest fan. He thanked his fans for their support and asked for privacy during a difficult time for him and his family.\n",
      "\n",
      " **Current Settings Summary:**\n",
      "\n",
      "üìù Summarizing your input... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully!\n",
      "\n",
      "=== Summary (Current Settings) ===\n",
      "Tiger Woods expressed gratitude for his mother's support and love, acknowledging her as his biggest fan. He thanked his fans for their support and asked for privacy during a difficult time for him and his family.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting program. Thank you for using the summarizer!\n"
     ]
    }
   ],
   "source": [
    "# Takes a long text input and summarizes it into a few sentences.\n",
    "# Uses the OpenAI API\n",
    "\n",
    "# Loads the necessary libraries\n",
    "import os\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Loads API key from environment variable\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"API key not found! Ensure it's set in your .env file.\")\n",
    "\n",
    "# Initializes the OpenAI Client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Sets the maximum text length to prevent long processing times\n",
    "MAX_INPUT_LENGTH = 5000  \n",
    "\n",
    "# Default Summarization Parameters\n",
    "temperature = 0.3  # Controls randomness (0 = deterministic, 1 = more creative)\n",
    "max_tokens = 150  # Limits summary length\n",
    "top_p = 0.9  # Controls diversity (higher = more diverse)\n",
    "frequency_penalty = 0.5  # Discourages word repetition\n",
    "presence_penalty = 0.5  # Encourages new topics\n",
    "\n",
    "def summarize_text(long_text, temp, tokens, top_p_value, freq_penalty, pres_penalty):\n",
    "    \"\"\"\n",
    "    Summarizes a given long text into a few sentences.\n",
    "    \"\"\"\n",
    "    print(\"\\nSummarizing your input... Please wait.\")  # Status message\n",
    "\n",
    "    # Ensures input is within safe limits\n",
    "    if len(long_text) > MAX_INPUT_LENGTH:\n",
    "        print(\"\\nInput text is too long! Trimming to fit the limit...\")\n",
    "        long_text = long_text[:MAX_INPUT_LENGTH]  # Trims the response\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()  # Tracks start time\n",
    "\n",
    "        print(\"Sending request to OpenAI API...\")  # Process status message\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Specifies the model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant that summarizes long texts into concise summaries.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Summarize the following text:\\n\\n{long_text}\"}\n",
    "            ],\n",
    "            temperature=temp,\n",
    "            max_tokens=tokens,\n",
    "            top_p=top_p_value,\n",
    "            frequency_penalty=freq_penalty,\n",
    "            presence_penalty=pres_penalty\n",
    "        )\n",
    "\n",
    "        print(\"Response received from OpenAI API.\")  # Status message\n",
    "\n",
    "        # Ensures the request does not take too long\n",
    "        if time.time() - start_time > 30:  # Sets the timeout to 30 seconds\n",
    "            print(\"Request took too long. Please try again with a shorter input.\")\n",
    "            return \"Summarization failed due to timeout.\"\n",
    "\n",
    "        # Extracts the summarized text\n",
    "        summary = response.choices[0].message.content.strip()\n",
    "        \n",
    "        print(\"\\nRequest completed successfully!\")  # Confirmation message\n",
    "        return summary\n",
    "\n",
    "    except openai.OpenAIError as e:  # Catches API errors\n",
    "        print(f\"\\nOpenAI API Error: {e}\")\n",
    "        return \"Summarization failed due to an API error.\"\n",
    "\n",
    "# Function to update summarization parameters\n",
    "def update_parameters():\n",
    "    global temperature, max_tokens, top_p, frequency_penalty, presence_penalty\n",
    "\n",
    "    print(\"\\nAdjust Summarization Parameters:\")\n",
    "    print(f\"1Ô∏è‚É£ Temperature (0: deterministic, 1: creative) | Current: {temperature}\")\n",
    "    print(f\"2Ô∏è‚É£ Max Tokens (Response length) | Current: {max_tokens}\")\n",
    "    print(f\"3Ô∏è‚É£ Top-p (Controls diversity) | Current: {top_p}\")\n",
    "    print(f\"4Ô∏è‚É£ Frequency Penalty (Repetition reduction) | Current: {frequency_penalty}\")\n",
    "    print(f\"5Ô∏è‚É£ Presence Penalty (Encourages new topics) | Current: {presence_penalty}\")\n",
    "\n",
    "    try:\n",
    "        temperature = float(input(\"üå°Ô∏è Enter new temperature (0-1): \") or temperature)\n",
    "        max_tokens = int(input(\"Enter max tokens (e.g., 50-300): \") or max_tokens)\n",
    "        top_p = float(input(\"Enter new top-p (0-1): \") or top_p)\n",
    "        frequency_penalty = float(input(\"Enter frequency penalty (0-1): \") or frequency_penalty)\n",
    "        presence_penalty = float(input(\"Enter presence penalty (0-1): \") or presence_penalty)\n",
    "        print(\"Settings updated successfully!\\n\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input! Keeping previous settings.\")\n",
    "\n",
    "# Processes each input immediately\n",
    "print(\"Enter text to summarize. Type **'settings'** to adjust parameters or **'exit'** to quit.\")\n",
    "while True:\n",
    "    long_text = input(\"\\nEnter your text: \")\n",
    "    \n",
    "    if long_text.lower() == \"exit\":\n",
    "        print(\"\\nExiting program. Thank you for using the summarizer!\")\n",
    "        break\n",
    "\n",
    "    if long_text.lower() == \"settings\":\n",
    "        update_parameters()\n",
    "        continue\n",
    "\n",
    "    if long_text.strip():\n",
    "        print(\"\\nProcessing your request...\")  # Status message\n",
    "        \n",
    "        # **Comparison Mode**: Summarizes with default and user-set parameters\n",
    "        print(\"\\n **Default Settings Summary:**\")\n",
    "        default_summary = summarize_text(long_text, 0.3, 150, 0.9, 0.5, 0.5)\n",
    "        print(\"\\n=== Summary (Default) ===\")\n",
    "        print(default_summary)\n",
    "        \n",
    "        print(\"\\n **Current Settings Summary:**\")\n",
    "        user_summary = summarize_text(long_text, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "        print(\"\\n=== Summary (Current Settings) ===\")\n",
    "        print(user_summary)\n",
    "\n",
    "    else:\n",
    "        print(\"\\n No text provided. Please enter a valid input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text in English to translate to Spanish. Type 'settings' to adjust parameters or 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  I have a brother and a sister.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing your request.\n",
      "\n",
      "Default Settings Translation:\n",
      "\n",
      "Translating your input... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully.\n",
      "\n",
      "=== Translation (Default) ===\n",
      "Tengo un hermano y una hermana.\n",
      "\n",
      "Current Settings Translation:\n",
      "\n",
      "Translating your input... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully.\n",
      "\n",
      "=== Translation (Current Settings) ===\n",
      "Tengo un hermano y una hermana.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting program. Thank you for using the translator.\n"
     ]
    }
   ],
   "source": [
    "# Creates a tool that translates text from one language to another using the OpenAI API.\n",
    "\n",
    "# Loads the necessary libraries\n",
    "import os\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Loads API key from environment variable\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"API key not found. Ensure it is set in your .env file.\")\n",
    "\n",
    "# Initializes the OpenAI Client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Maximum text length to prevent long processing times\n",
    "MAX_INPUT_LENGTH = 5000  \n",
    "\n",
    "# Default Translation Parameters\n",
    "temperature = 0.3  # Controls randomness (0 = deterministic, 1 = more creative)\n",
    "max_tokens = 250  # Limits translation length\n",
    "top_p = 0.9  # Controls diversity (higher = more diverse)\n",
    "frequency_penalty = 0.5  # Discourages word repetition\n",
    "presence_penalty = 0.5  # Encourages new words\n",
    "\n",
    "def translate_text(text, temp, tokens, top_p_value, freq_penalty, pres_penalty):\n",
    "    \"\"\"\n",
    "    Translates a given English text into Spanish.\n",
    "    \"\"\"\n",
    "    print(\"\\nTranslating your input... Please wait.\")  \n",
    "\n",
    "    # Ensures input is within safe limits\n",
    "    if len(text) > MAX_INPUT_LENGTH:\n",
    "        print(\"\\nInput text is too long. Trimming to fit the limit.\")\n",
    "        text = text[:MAX_INPUT_LENGTH]  \n",
    "\n",
    "    try:\n",
    "        start_time = time.time()  \n",
    "\n",
    "        print(\"Sending request to OpenAI API...\")  \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant that translates English text to Spanish.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Translate the following English text into Spanish:\\n\\n{text}\"}\n",
    "            ],\n",
    "            temperature=temp,\n",
    "            max_tokens=tokens,\n",
    "            top_p=top_p_value,\n",
    "            frequency_penalty=freq_penalty,\n",
    "            presence_penalty=pres_penalty\n",
    "        )\n",
    "\n",
    "        print(\"Response received from OpenAI API.\")  \n",
    "\n",
    "        # Ensures the request does not take too long\n",
    "        if time.time() - start_time > 30:  \n",
    "            print(\"Request took too long. Please try again with a shorter input.\")\n",
    "            return \"Translation failed due to timeout.\"\n",
    "\n",
    "        # Extracts the translated text\n",
    "        translation = response.choices[0].message.content.strip()\n",
    "        \n",
    "        print(\"\\nRequest completed successfully.\")  \n",
    "        return translation\n",
    "\n",
    "    except openai.OpenAIError as e:  \n",
    "        print(f\"\\nOpenAI API Error: {e}\")\n",
    "        return \"Translation failed due to an API error.\"\n",
    "\n",
    "# Function to update translation parameters\n",
    "def update_parameters():\n",
    "    global temperature, max_tokens, top_p, frequency_penalty, presence_penalty\n",
    "\n",
    "    print(\"\\nAdjust Translation Parameters:\")\n",
    "    print(f\"1. Temperature (0: deterministic, 1: creative) | Current: {temperature}\")\n",
    "    print(f\"2. Max Tokens (Translation length) | Current: {max_tokens}\")\n",
    "    print(f\"3. Top-p (Controls diversity) | Current: {top_p}\")\n",
    "    print(f\"4. Frequency Penalty (Repetition reduction) | Current: {frequency_penalty}\")\n",
    "    print(f\"5. Presence Penalty (Encourages new words) | Current: {presence_penalty}\")\n",
    "\n",
    "    try:\n",
    "        temperature = float(input(\"Enter new temperature (0-1): \") or temperature)\n",
    "        max_tokens = int(input(\"Enter max tokens (e.g., 100-500): \") or max_tokens)\n",
    "        top_p = float(input(\"Enter new top-p (0-1): \") or top_p)\n",
    "        frequency_penalty = float(input(\"Enter frequency penalty (0-1): \") or frequency_penalty)\n",
    "        presence_penalty = float(input(\"Enter presence penalty (0-1): \") or presence_penalty)\n",
    "        print(\"Settings updated successfully.\\n\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Keeping previous settings.\")\n",
    "\n",
    "# Processes each input immediately\n",
    "print(\"Enter text in English to translate to Spanish. Type 'settings' to adjust parameters or 'exit' to quit.\")\n",
    "while True:\n",
    "    text = input(\"\\nEnter your text: \")\n",
    "    \n",
    "    if text.lower() == \"exit\":\n",
    "        print(\"\\nExiting program. Thank you for using the translator.\")\n",
    "        break\n",
    "\n",
    "    if text.lower() == \"settings\":\n",
    "        update_parameters()\n",
    "        continue\n",
    "\n",
    "    if text.strip():\n",
    "        print(\"\\nProcessing your request.\")     \n",
    "        \n",
    "        # Comparison Mode: Translates with default and user-set parameters\n",
    "        print(\"\\nDefault Settings Translation:\")\n",
    "        default_translation = translate_text(text, 0.3, 250, 0.9, 0.5, 0.5)\n",
    "        print(\"\\n=== Translation (Default) ===\")\n",
    "        print(default_translation)\n",
    "        \n",
    "        print(\"\\nCurrent Settings Translation:\")\n",
    "        user_translation = translate_text(text, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "        print(\"\\n=== Translation (Current Settings) ===\")\n",
    "        print(user_translation)\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo text provided. Please enter a valid input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the Parameters\n",
    "\n",
    "- lower temperature values provide more accurate, predictable and literal translations. Higher values result in more paraphrased translations and potentially altered sentence structure. For accurate translations 0.3 works great; only increase if more flexible results are desired.\n",
    "\n",
    "- lower token values (50-100) result in shorter, cut-off translations. Higher values result in longer, more complete translations.\n",
    "\n",
    "- if the max_tokens are too low, it may result in truncated outputs. Sentence translations should be at 150-200 and for paragraphs, 300-500\n",
    "\n",
    "- lower top_p values result in safer translations, higher values (0.8-1.0) in less predictable phrasing. A value of 0.9 provides good balance of accuracy and diversity. Also, if a high temperature (greater than or equal to 0.7) is used, reduce the top_p to avoid overly random results.\n",
    "\n",
    "- lower frequency_penalty values may result in repeat words within longer translations. Higher values avoid repeated words, but may result in unnatural translations.\n",
    "\n",
    "- lower presence_penalty values sticks closely to the input text. Higher values result in more diverse vocabulary and new words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text to analyze sentiment. Type 'settings' to adjust parameters or 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  I have a brother and a sister.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing your request.\n",
      "\n",
      "Default Settings Sentiment Analysis:\n",
      "\n",
      "Analyzing sentiment... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully.\n",
      "\n",
      "=== Sentiment (Default) ===\n",
      "Neutral\n",
      "\n",
      "Current Settings Sentiment Analysis:\n",
      "\n",
      "Analyzing sentiment... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully.\n",
      "\n",
      "=== Sentiment (Current Settings) ===\n",
      "Neutral\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your text:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting program. Thank you for using the sentiment analysis tool.\n"
     ]
    }
   ],
   "source": [
    "# Creates a sentiment analysis tool that determines the sentiment of a given text (Positive, Negative, Neutral).\n",
    "\n",
    "# Loads the necessary libraries\n",
    "import os\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Loads API key from environment variable\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"API key not found. Ensure it is set in your .env file.\")\n",
    "\n",
    "# Initializes the OpenAI Client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Maximum text length to prevent long processing times\n",
    "MAX_INPUT_LENGTH = 5000  \n",
    "\n",
    "# Default Sentiment Analysis Parameters\n",
    "temperature = 0.3  # Controls randomness (0 = deterministic, 1 = more creative)\n",
    "max_tokens = 10  # Limits response length\n",
    "top_p = 0.9  # Controls diversity (higher = more diverse)\n",
    "frequency_penalty = 0.5  # Discourages word repetition\n",
    "presence_penalty = 0.5  # Encourages new words\n",
    "\n",
    "def analyze_sentiment(text, temp, tokens, top_p_value, freq_penalty, pres_penalty):\n",
    "    \"\"\"\n",
    "    Determines the sentiment of a given text (Positive, Negative, Neutral).\n",
    "    \"\"\"\n",
    "    print(\"\\nAnalyzing sentiment... Please wait.\")  \n",
    "\n",
    "    # Ensures input is within safe limits\n",
    "    if len(text) > MAX_INPUT_LENGTH:\n",
    "        print(\"\\nInput text is too long. Trimming to fit the limit.\")\n",
    "        text = text[:MAX_INPUT_LENGTH]  \n",
    "\n",
    "    try:\n",
    "        start_time = time.time()  \n",
    "\n",
    "        print(\"Sending request to OpenAI API...\")  \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant that performs sentiment analysis. You classify text as Positive, Negative, or Neutral.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Analyze the sentiment of the following text and classify it as Positive, Negative, or Neutral:\\n\\n{text}\"}\n",
    "            ],\n",
    "            temperature=temp,\n",
    "            max_tokens=tokens,\n",
    "            top_p=top_p_value,\n",
    "            frequency_penalty=freq_penalty,\n",
    "            presence_penalty=pres_penalty\n",
    "        )\n",
    "\n",
    "        print(\"Response received from OpenAI API.\")  \n",
    "\n",
    "        # Ensures the request does not take too long\n",
    "        if time.time() - start_time > 30:  \n",
    "            print(\"Request took too long. Please try again with a shorter input.\")\n",
    "            return \"Sentiment analysis failed due to timeout.\"\n",
    "\n",
    "        # Extracts the sentiment classification\n",
    "        sentiment = response.choices[0].message.content.strip()\n",
    "        \n",
    "        print(\"\\nRequest completed successfully.\")  \n",
    "        return sentiment\n",
    "\n",
    "    except openai.OpenAIError as e:  \n",
    "        print(f\"\\nOpenAI API Error: {e}\")\n",
    "        return \"Sentiment analysis failed due to an API error.\"\n",
    "\n",
    "# Function to update sentiment analysis parameters\n",
    "def update_parameters():\n",
    "    global temperature, max_tokens, top_p, frequency_penalty, presence_penalty\n",
    "\n",
    "    print(\"\\nAdjust Sentiment Analysis Parameters:\")\n",
    "    print(f\"1. Temperature (0: deterministic, 1: creative) | Current: {temperature}\")\n",
    "    print(f\"2. Max Tokens (Response length) | Current: {max_tokens}\")\n",
    "    print(f\"3. Top-p (Controls diversity) | Current: {top_p}\")\n",
    "    print(f\"4. Frequency Penalty (Repetition reduction) | Current: {frequency_penalty}\")\n",
    "    print(f\"5. Presence Penalty (Encourages new words) | Current: {presence_penalty}\")\n",
    "\n",
    "    try:\n",
    "        temperature = float(input(\"Enter new temperature (0-1): \") or temperature)\n",
    "        max_tokens = int(input(\"Enter max tokens (e.g., 5-50): \") or max_tokens)\n",
    "        top_p = float(input(\"Enter new top-p (0-1): \") or top_p)\n",
    "        frequency_penalty = float(input(\"Enter frequency penalty (0-1): \") or frequency_penalty)\n",
    "        presence_penalty = float(input(\"Enter presence penalty (0-1): \") or presence_penalty)\n",
    "        print(\"Settings updated successfully.\\n\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Keeping previous settings.\")\n",
    "\n",
    "# Processes each input immediately\n",
    "print(\"Enter text to analyze sentiment. Type 'settings' to adjust parameters or 'exit' to quit.\")\n",
    "while True:\n",
    "    text = input(\"\\nEnter your text: \")\n",
    "    \n",
    "    if text.lower() == \"exit\":\n",
    "        print(\"\\nExiting program. Thank you for using the sentiment analysis tool.\")\n",
    "        break\n",
    "\n",
    "    if text.lower() == \"settings\":\n",
    "        update_parameters()\n",
    "        continue\n",
    "\n",
    "    if text.strip():\n",
    "        print(\"\\nProcessing your request.\")     \n",
    "        \n",
    "        # Comparison Mode: Analyzes sentiment with default and user-set parameters\n",
    "        print(\"\\nDefault Settings Sentiment Analysis:\")\n",
    "        default_sentiment = analyze_sentiment(text, 0.3, 10, 0.9, 0.5, 0.5)\n",
    "        print(\"\\n=== Sentiment (Default) ===\")\n",
    "        print(default_sentiment)\n",
    "        \n",
    "        print(\"\\nCurrent Settings Sentiment Analysis:\")\n",
    "        user_sentiment = analyze_sentiment(text, temperature, max_tokens, top_p, frequency_penalty, presence_penalty)\n",
    "        print(\"\\n=== Sentiment (Current Settings) ===\")\n",
    "        print(user_sentiment)\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo text provided. Please enter a valid input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the Parameters\n",
    "\n",
    "- temperature: lower values provide more consistent and accurate sentiment classifications.\n",
    "- max_tokens: lower values result in shorter, precise responses, higher values might provide unnecessary explanations.\n",
    "- top_p: lower values (0.1-0.5) provide less diverse, more focused responses. Higher values may introduce variability in the classification.\n",
    "- frequency_penalty: lower values may result in repeat words within longer responses. Higher values can sometimes result in unnatural responses.\n",
    "- presence_penalty: lower values (0-0.3) provides results close to the standard classifications. Higher values may insert new and varied responses.\n",
    "- n: an n=1 results in only one sentiment classification. A value of 3 could be useful for comparisons as it returns 3 possible classifications.\n",
    "- -logprobs: A value of 5 can be useful for detailed analysis purposes but should be removed for normal use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a prompt to generate text. Type 'settings' to adjust parameters, 'examples' to see predefined prompts, or 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt (or command):  Taylor Swift\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing your request.\n",
      "\n",
      "Default Settings Text Completion:\n",
      "\n",
      "Generating text... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully.\n",
      "\n",
      "=== Response 1 (Default) ===\n",
      "Taylor Swift is a renowned singer-songwriter known for her catchy pop and country music. With numerous chart-topping hits and multiple Grammy Awards to her name, she has captivated audiences worldwide with her heartfelt lyrics and relatable storytelling. Taylor's career has seen her evolve from a teenage country sensation to a global pop icon, all while staying true to her authentic self. Her music often explores themes of love, heartbreak, and personal growth, resonating with fans of all ages. In addition to her\n",
      "\n",
      "=== Response 2 (Default) ===\n",
      "Taylor Swift is a multi-talented singer-songwriter who has made a huge impact on the music industry. Known for her catchy melodies, heartfelt lyrics, and relatable storytelling, she has amassed a large and dedicated fan base over the years. With numerous hit songs and successful albums to her name, Taylor Swift continues to reinvent herself and push boundaries in the world of pop music. Her ability to connect with her audience through her music and genuine personality has solidified her status as one of the most\n",
      "\n",
      "=== Response 3 (Default) ===\n",
      "Taylor Swift is a highly successful singer-songwriter known for her emotional and relatable lyrics. With multiple Grammy Awards and hit songs like \"Love Story\" and \"Shake It Off,\" she has become one of the biggest names in the music industry. Taylor is also known for her philanthropy work, activism, and strong connection with her fans.\n",
      "\n",
      "Current Settings Text Completion:\n",
      "\n",
      "Generating text... Please wait.\n",
      "Sending request to OpenAI API...\n",
      "Response received from OpenAI API.\n",
      "\n",
      "Request completed successfully.\n",
      "\n",
      "=== Response 1 (Current Settings) ===\n",
      "Taylor Swift is a highly successful American singer-songwriter known for her catchy pop songs and heartfelt lyrics. With numerous hit singles and albums to her name, she has won multiple Grammy Awards and has a huge fan following around the world. Taylor Swift's music often reflects on love, heartbreak, and personal growth, resonating with listeners of all ages. In addition to her music career, she is also involved in various philanthropic efforts and uses her platform to advocate for important social issues.\n",
      "\n",
      "=== Response 2 (Current Settings) ===\n",
      "Taylor Swift is a renowned singer-songwriter known for her catchy pop tunes and heartfelt lyrics. With numerous hit songs like \"Love Story,\" \"Shake It Off,\" and \"Blank Space,\" she has won multiple Grammy Awards and has a massive fan following worldwide. Taylor Swift's music often reflects her personal experiences and relationships, making her songs relatable to many listeners. In addition to her musical talents, she is also recognized for her advocacy for artists' rights and charitable work. Overall, Taylor Swift has\n",
      "\n",
      "=== Response 3 (Current Settings) ===\n",
      "Taylor Swift is a singer-songwriter known for her catchy pop tunes and heartfelt lyrics. With multiple albums under her belt, she has won numerous awards and amassed a huge fan base around the world. Taylor's music often explores themes of love, heartbreak, and personal growth, resonating with listeners of all ages. In addition to her musical talents, she is also recognized for her philanthropic efforts and advocacy on various social issues. Overall, Taylor Swift continues to be a prominent figure in the music industry\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt (or command):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exiting program. Thank you for using the text generator.\n"
     ]
    }
   ],
   "source": [
    "# Creates a text completion application that generates text based on an initial prompt.\n",
    "\n",
    "# Loads the necessary libraries\n",
    "import os\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Loads API key from environment variable\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"API key not found. Ensure it is set in your .env file.\")\n",
    "\n",
    "# Initializes the OpenAI Client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Maximum text length to prevent long processing times\n",
    "MAX_INPUT_LENGTH = 1000  \n",
    "\n",
    "# Default Text Generation Parameters\n",
    "temperature = 0.7  # Controls randomness (0 = deterministic, 1 = highly creative)\n",
    "max_tokens = 100  # Limits response length\n",
    "top_p = 0.9  # Controls response diversity\n",
    "frequency_penalty = 0.5  # Reduces word repetition\n",
    "presence_penalty = 0.5  # Encourages introducing new topics\n",
    "n = 3  # Number of responses to generate\n",
    "\n",
    "# Predefined prompt examples for testing different scenarios\n",
    "predefined_prompts = {\n",
    "    \"story\": \"Once upon a time in a futuristic city, a scientist made a groundbreaking discovery...\",\n",
    "    \"email\": \"Write a professional email to a colleague, requesting a meeting for next week.\",\n",
    "    \"advice\": \"What are some key habits for staying productive throughout the day?\",\n",
    "    \"code\": \"Write a Python function that calculates the factorial of a number.\",\n",
    "}\n",
    "\n",
    "def generate_text(prompt, temp, tokens, top_p_value, freq_penalty, pres_penalty, num_responses):\n",
    "    \"\"\"\n",
    "    Generates text based on an initial prompt using OpenAI's chat model.\n",
    "    \"\"\"\n",
    "    print(\"\\nGenerating text... Please wait.\")  \n",
    "\n",
    "    # Ensures input is within safe limits\n",
    "    if len(prompt) > MAX_INPUT_LENGTH:\n",
    "        print(\"\\nInput prompt is too long. Trimming to fit the limit.\")\n",
    "        prompt = prompt[:MAX_INPUT_LENGTH]  \n",
    "\n",
    "    try:\n",
    "        start_time = time.time()  \n",
    "\n",
    "        print(\"Sending request to OpenAI API...\")  \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",  \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI that generates text based on a given prompt.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temp,\n",
    "            max_tokens=tokens,\n",
    "            top_p=top_p_value,\n",
    "            frequency_penalty=freq_penalty,\n",
    "            presence_penalty=pres_penalty,\n",
    "            n=num_responses\n",
    "        )\n",
    "\n",
    "        print(\"Response received from OpenAI API.\")  \n",
    "\n",
    "        # Ensures the request does not take too long\n",
    "        if time.time() - start_time > 30:  \n",
    "            print(\"Request took too long. Please try again with a shorter input.\")\n",
    "            return [\"Text generation failed due to timeout.\"]\n",
    "\n",
    "        # Extracts multiple responses\n",
    "        generated_texts = [choice.message.content.strip() for choice in response.choices]\n",
    "\n",
    "        print(\"\\nRequest completed successfully.\")  \n",
    "        return generated_texts\n",
    "\n",
    "    except openai.OpenAIError as e:  \n",
    "        print(f\"\\nOpenAI API Error: {e}\")\n",
    "        return [\"Text generation failed due to an API error.\"]\n",
    "\n",
    "# Function to update text generation parameters\n",
    "def update_parameters():\n",
    "    global temperature, max_tokens, top_p, frequency_penalty, presence_penalty, n\n",
    "\n",
    "    print(\"\\nAdjust Text Generation Parameters:\")\n",
    "    print(f\"1. Temperature (0: deterministic, 1: creative) | Current: {temperature}\")\n",
    "    print(f\"2. Max Tokens (Response length) | Current: {max_tokens}\")\n",
    "    print(f\"3. Top-p (Controls diversity) | Current: {top_p}\")\n",
    "    print(f\"4. Frequency Penalty (Repetition reduction) | Current: {frequency_penalty}\")\n",
    "    print(f\"5. Presence Penalty (Encourages new words) | Current: {presence_penalty}\")\n",
    "    print(f\"6. Number of Responses (Multiple outputs for comparison) | Current: {n}\")\n",
    "\n",
    "    try:\n",
    "        temperature = float(input(\"Enter new temperature (0-1): \") or temperature)\n",
    "        max_tokens = int(input(\"Enter max tokens (e.g., 50-500): \") or max_tokens)\n",
    "        top_p = float(input(\"Enter new top-p (0-1): \") or top_p)\n",
    "        frequency_penalty = float(input(\"Enter frequency penalty (0-1): \") or frequency_penalty)\n",
    "        presence_penalty = float(input(\"Enter presence penalty (0-1): \") or presence_penalty)\n",
    "        n = int(input(\"Enter number of responses (e.g., 1-5): \") or n)\n",
    "        print(\"Settings updated successfully.\\n\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Keeping previous settings.\")\n",
    "\n",
    "# Processes each input immediately\n",
    "print(\"Enter a prompt to generate text. Type 'settings' to adjust parameters, 'examples' to see predefined prompts, or 'exit' to quit.\")\n",
    "while True:\n",
    "    user_input = input(\"\\nEnter your prompt (or command): \")\n",
    "    \n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"\\nExiting program. Thank you for using the text generator.\")\n",
    "        break\n",
    "\n",
    "    if user_input.lower() == \"settings\":\n",
    "        update_parameters()\n",
    "        continue\n",
    "\n",
    "    if user_input.lower() == \"examples\":\n",
    "        print(\"\\nPredefined Prompts:\")\n",
    "        for key, value in predefined_prompts.items():\n",
    "            print(f\" - {key}: {value}\")\n",
    "        continue\n",
    "\n",
    "    if user_input.lower() in predefined_prompts:\n",
    "        user_input = predefined_prompts[user_input.lower()]\n",
    "\n",
    "    if user_input.strip():\n",
    "        print(\"\\nProcessing your request.\")     \n",
    "\n",
    "        # Generates text with default and user-set parameters for comparison\n",
    "        print(\"\\nDefault Settings Text Completion:\")\n",
    "        default_texts = generate_text(user_input, 0.7, 100, 0.9, 0.5, 0.5, 3)\n",
    "        \n",
    "        for i, text in enumerate(default_texts, start=1):\n",
    "            print(f\"\\n=== Response {i} (Default) ===\")\n",
    "            print(text)\n",
    "\n",
    "        print(\"\\nCurrent Settings Text Completion:\")\n",
    "        user_texts = generate_text(user_input, temperature, max_tokens, top_p, frequency_penalty, presence_penalty, n)\n",
    "        \n",
    "        for i, text in enumerate(user_texts, start=1):\n",
    "            print(f\"\\n=== Response {i} (Current Settings) ===\")\n",
    "            print(text)\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo prompt provided. Please enter a valid input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the Parameters\n",
    "\n",
    "- temperature: controls the creativity\n",
    "- max_tokens: limits the response length\n",
    "- top_p: controls response diversity\n",
    "- frequency_penalty: avoids word repetition\n",
    "- presence_penalty: encourages new words\n",
    "- n: generates multiple responses\n",
    "- stop: controls where the response ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 (TensorFlow)",
   "language": "python",
   "name": "pyenv_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
